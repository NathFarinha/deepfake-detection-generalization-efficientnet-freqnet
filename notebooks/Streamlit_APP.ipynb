{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kz9M1h0UcXOn",
        "outputId": "560f29fd-43c1-492f-a3dd-3fd6dff3294f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FreqNet-DeepfakeDetection'...\n",
            "remote: Enumerating objects: 45, done.\u001b[K\n",
            "remote: Counting objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 45 (delta 1), reused 1 (delta 1), pack-reused 43 (from 2)\u001b[K\n",
            "Receiving objects: 100% (45/45), 8.62 MiB | 17.20 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/chuangchuangtan/FreqNet-DeepfakeDetection.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D0O52AYcXJY",
        "outputId": "ac1cb86d-b8a3-4f2b-b592-79684abf4a73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/FreqNet-DeepfakeDetection\n"
          ]
        }
      ],
      "source": [
        "%cd FreqNet-DeepfakeDetection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp58t5YhcV4f",
        "outputId": "979eec76-5e49-49bf-ceb8-76f56b220886"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2.0.2)\n",
            "Requirement already satisfied: opencv_python in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (4.12.0.88)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (11.3.0)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (0.23.0+cu126)\n",
            "Collecting gdown==4.7.1 (from -r requirements.txt (line 8))\n",
            "  Downloading gdown-4.7.1-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown==4.7.1->-r requirements.txt (line 8)) (3.19.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown==4.7.1->-r requirements.txt (line 8)) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from gdown==4.7.1->-r requirements.txt (line 8)) (1.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown==4.7.1->-r requirements.txt (line 8)) (4.67.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown==4.7.1->-r requirements.txt (line 8)) (4.13.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 2)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 2)) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (4.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.2.0->-r requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown==4.7.1->-r requirements.txt (line 8)) (2.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.2.0->-r requirements.txt (line 6)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown==4.7.1->-r requirements.txt (line 8)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown==4.7.1->-r requirements.txt (line 8)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown==4.7.1->-r requirements.txt (line 8)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown==4.7.1->-r requirements.txt (line 8)) (2025.8.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown==4.7.1->-r requirements.txt (line 8)) (1.7.1)\n",
            "Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 5.2.0\n",
            "    Uninstalling gdown-5.2.0:\n",
            "      Successfully uninstalled gdown-5.2.0\n",
            "Successfully installed gdown-4.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDFw6GEtcViJ",
        "outputId": "bec1c6ad-f0cc-4205-89fd-71f49d360dae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown==4.7.1 in /usr/local/lib/python3.12/dist-packages (4.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown==4.7.1) (3.19.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown==4.7.1) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from gdown==4.7.1) (1.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown==4.7.1) (4.67.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown==4.7.1) (4.13.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown==4.7.1) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown==4.7.1) (4.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown==4.7.1) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown==4.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown==4.7.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown==4.7.1) (2025.8.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown==4.7.1) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown==4.7.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07qSr2f2comd",
        "outputId": "0eb60410-a64f-4e9e-afdf-1664768dca24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (4.7.1)\n",
            "Collecting gdown\n",
            "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.19.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.8.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.7.1\n",
            "    Uninstalling gdown-4.7.1:\n",
            "      Successfully uninstalled gdown-4.7.1\n",
            "Successfully installed gdown-5.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U gdown\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_mhvIPUcojQ"
      },
      "outputs": [],
      "source": [
        "#!sed -i 's/\\r$//' /content/FreqNet-DeepfakeDetection/download_dataset.sh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKvoLckccogn"
      },
      "outputs": [],
      "source": [
        "#!chmod 777 ./download_dataset.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiDjVz61coeJ"
      },
      "outputs": [],
      "source": [
        "#!/content/FreqNet-DeepfakeDetection/download_dataset.sh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBx6BW6kcobd",
        "outputId": "b8fc4640-d3da-441c-dc48-5a359cc2a094"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNFsPzXVO-a4"
      },
      "source": [
        "# Deepfake Detection Application - Streamlit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdORCTWreYd_"
      },
      "source": [
        "To enable the detections in this notebook, you must ensure that in the 'Runtime' tab, under 'Change runtime type', the mode with a GPU is selected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uzYiCe2d5JX"
      },
      "source": [
        "To access some examples for testing the App, clone the following repository and use the images and videos from the 'samples' folder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW34ipK1FmfI",
        "outputId": "ceefe1d9-c9fb-44b4-f6f2-ff7a9af8964a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TCC_DeepFake_Detection_v1'...\n",
            "remote: Enumerating objects: 531, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 531 (delta 49), reused 6 (delta 6), pack-reused 456 (from 1)\u001b[K\n",
            "Receiving objects: 100% (531/531), 96.73 MiB | 15.32 MiB/s, done.\n",
            "Resolving deltas: 100% (203/203), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NathFarinha/TCC_DeepFake_Detection_v1.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXnMXNyveLC-"
      },
      "source": [
        "**Organizing the Environment for App Execution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qs1zT2OLPAtS",
        "outputId": "0f1b6a8c-e935-47fb-a7f8-c21dac0a71e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m118.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKjLp5GzFmco",
        "outputId": "ae64fafb-fe8b-44a8-f125-733903358d2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'icpr2020dfdc'...\n",
            "remote: Enumerating objects: 656, done.\u001b[K\n",
            "remote: Counting objects: 100% (119/119), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 656 (delta 101), reused 87 (delta 83), pack-reused 537 (from 1)\u001b[K\n",
            "Receiving objects: 100% (656/656), 99.64 MiB | 16.15 MiB/s, done.\n",
            "Resolving deltas: 100% (341/341), done.\n",
            "Collecting efficientnet-pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from efficientnet-pytorch) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet-pytorch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet-pytorch) (4.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet-pytorch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet-pytorch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet-pytorch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet-pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet-pytorch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet-pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet-pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet-pytorch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet-pytorch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet-pytorch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet-pytorch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet-pytorch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet-pytorch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet-pytorch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet-pytorch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet-pytorch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet-pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet-pytorch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet-pytorch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet-pytorch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->efficientnet-pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->efficientnet-pytorch) (3.0.2)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16426 sha256=d204f5f82c4e794f4558f8158dc55855904846a9a9aea2625261745caa02e5a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/3f/43/e6271c7026fe08c185da2be23c98c8e87477d3db63f41f32ad\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/albu/albumentations /tmp/pip-req-build-dage5e33\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 2.0.8 requires albucore==0.0.24, but you have albucore 0.0.28 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m/content/icpr2020dfdc\n"
          ]
        }
      ],
      "source": [
        "# Cloning 'Video Face Manipulation Detection Through Ensemble of CNNs' repository\n",
        "!git clone https://github.com/polimi-ispl/icpr2020dfdc\n",
        "!pip install efficientnet-pytorch\n",
        "!pip install -U git+https://github.com/albu/albumentations > /dev/null\n",
        "%cd icpr2020dfdc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le66uwSHPE8n"
      },
      "source": [
        "**Streamlit Deepfake Detection App**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUfipuBUegAN",
        "outputId": "6ae10853-bc08-4b91-a432-d67fcc26fb25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.model_zoo import load_url\n",
        "from scipy.special import expit\n",
        "from PIL import Image\n",
        "import streamlit as st\n",
        "import os\n",
        "import tempfile\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from blazeface import FaceExtractor, BlazeFace, VideoReader\n",
        "from architectures import fornet, weights\n",
        "from isplutils import utils\n",
        "\n",
        "# ===== FREQNET IMPORTS =====\n",
        "# Adjusting sys path to import FreqNet model definition\n",
        "import sys\n",
        "sys.path.append(\"/content/FreqNet-DeepfakeDetection\")\n",
        "from networks.freqnet import freqnet\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "face_policy = 'scale'\n",
        "face_size = 224\n",
        "frames_per_video = 32\n",
        "\n",
        "# Initialize BlazeFace (Used by the original paper's models)\n",
        "facedet = BlazeFace().to(device)\n",
        "# NOTE: Assuming 'blazeface/blazeface.pth' and 'blazeface/anchors.npy' are available in the environment\n",
        "facedet.load_weights(\"blazeface/blazeface.pth\")\n",
        "facedet.load_anchors(\"blazeface/anchors.npy\")\n",
        "videoreader = VideoReader(verbose=False)\n",
        "video_read_fn = lambda x: videoreader.read_frames(x, num_frames=frames_per_video)\n",
        "face_extractor = FaceExtractor(video_read_fn=video_read_fn, facedet=facedet)\n",
        "\n",
        "# ===== FREQNET FUNCTIONS =====\n",
        "def load_freqnet_model(model_path):\n",
        "    \"\"\"Loads the FreqNet model state dictionary.\"\"\"\n",
        "    model = freqnet(num_classes=1)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device), strict=True)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def preprocess_frame_freqnet(frame):\n",
        "    \"\"\"Preprocesses a single video frame for FreqNet (resize, normalization).\"\"\"\n",
        "    frame = cv2.resize(frame, (299, 299))\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    frame = frame.astype(np.float32) / 255.0\n",
        "    frame = (frame - 0.5) / 0.5 # Normalize to [-1, 1]\n",
        "    tensor = torch.from_numpy(frame).permute(2, 0, 1).unsqueeze(0)\n",
        "    return tensor\n",
        "\n",
        "def predict_freqnet(file_path, is_video, model):\n",
        "    \"\"\"Handles prediction logic specifically for FreqNet (image or video).\"\"\"\n",
        "    scores = []\n",
        "    if not is_video:\n",
        "        # Image prediction\n",
        "        frame = cv2.imread(file_path)\n",
        "        tensor = preprocess_frame_freqnet(frame).to(device)\n",
        "        with torch.no_grad():\n",
        "            score = torch.sigmoid(model(tensor)).item()\n",
        "        scores.append(score)\n",
        "    else:\n",
        "        # Video prediction (sampling every 5th frame)\n",
        "        cap = cv2.VideoCapture(file_path)\n",
        "        frame_count = 0\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame_count += 1\n",
        "            if frame_count % 5 == 0:\n",
        "                tensor = preprocess_frame_freqnet(frame).to(device)\n",
        "                with torch.no_grad():\n",
        "                    score = torch.sigmoid(model(tensor)).item()\n",
        "                scores.append(score)\n",
        "        cap.release()\n",
        "\n",
        "    avg_score = np.mean(scores) if scores else 0\n",
        "    # Thresholding at 0.6 as used in some deepfake contexts\n",
        "    prediction = \"FAKE\" if avg_score >= 0.6 else \"REAL\"\n",
        "    return prediction, avg_score\n",
        "\n",
        "# ===== MAIN DETECTION FUNCTION (for ForNet/EfficientNet models) =====\n",
        "def detect_deep_fake(uploaded_file, selected_model, selected_dataset):\n",
        "    \"\"\"Detects deepfakes using the selected ForNet-based model.\"\"\"\n",
        "\n",
        "    # Save uploaded file to a temporary directory\n",
        "    temp_dir = tempfile.mkdtemp()\n",
        "    temp_file_path = os.path.join(temp_dir, uploaded_file.name)\n",
        "    with open(temp_file_path, 'wb') as temp_file:\n",
        "        temp_file.write(uploaded_file.read())\n",
        "\n",
        "    # Handle FreqNet separately\n",
        "    if selected_model == \"FreqNet\":\n",
        "        model_path = \"/content/FreqNet-DeepfakeDetection/4-classes-freqnet-v2.pth\"\n",
        "        is_video = uploaded_file.type.startswith('video')\n",
        "        # FreqNet has its own prediction logic\n",
        "        return predict_freqnet(temp_file_path, is_video, load_freqnet_model(model_path))\n",
        "\n",
        "    # --- ForNet Models (EfficientNet family) ---\n",
        "\n",
        "    model_url = weights.weight_url['{:s}_{:s}'.format(selected_model, selected_dataset)]\n",
        "    net = getattr(fornet, selected_model)().eval().to(device)\n",
        "    # Load weights from URL\n",
        "    net.load_state_dict(load_url(model_url, map_location=device, check_hash=True))\n",
        "    transf = utils.get_transformer(face_policy, face_size, net.get_normalizer(), train=False)\n",
        "\n",
        "    if uploaded_file.type.startswith('image'):\n",
        "        # Image processing\n",
        "        im = Image.open(temp_file_path)\n",
        "        im_faces = face_extractor.process_image(img=im)\n",
        "        im_face = im_faces['faces'][0] if len(im_faces['faces']) > 0 else None\n",
        "\n",
        "        if im_face is not None:\n",
        "            faces_t = torch.stack([transf(image=im_face)['image']])\n",
        "            with torch.no_grad():\n",
        "                faces_pred = net(faces_t.to(device)).cpu().numpy().flatten()\n",
        "\n",
        "            # expit converts logits to probabilities (0-1)\n",
        "            avg_score = expit(faces_pred.mean())\n",
        "            prediction = 'FAKE' if avg_score >= 0.6 else 'REAL'\n",
        "        else:\n",
        "            return 'Face could not be detected in the image.', 0.0\n",
        "\n",
        "    elif uploaded_file.type.startswith('video'):\n",
        "        # Video processing\n",
        "        vid_faces = face_extractor.process_video(temp_file_path)\n",
        "\n",
        "        # Stack all detected faces from sampled frames\n",
        "        faces_t = torch.stack([transf(image=frame['faces'][0])['image']\n",
        "                               for frame in vid_faces if len(frame['faces'])])\n",
        "\n",
        "        if faces_t.nelement() == 0:\n",
        "            return 'No faces detected in video samples.', 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Get logits from the network\n",
        "            faces_pred = net(faces_t.to(device)).cpu().numpy().flatten()\n",
        "\n",
        "        # expit converts logits to probabilities (0-1)\n",
        "        avg_score = expit(faces_pred.mean())\n",
        "        prediction = 'FAKE' if avg_score >= 0.6 else 'REAL'\n",
        "    else:\n",
        "        return 'Unsupported file type.', 0.0\n",
        "\n",
        "    return prediction, avg_score\n",
        "\n",
        "# ===== STREAMLIT APP LAYOUT =====\n",
        "st.set_page_config(page_title=\"Deepfake Detection\", page_icon=\"✅\", layout=\"wide\")\n",
        "page = st.sidebar.radio(\"Select a page\", [\"Deepfake Detection\", \"About the Author\"])\n",
        "\n",
        "if page == \"Deepfake Detection\":\n",
        "    st.title('Deepfake Detection')\n",
        "    uploaded_file = st.file_uploader('Upload an image or video', type=['jpg', 'jpeg', 'png', 'mp4'])\n",
        "\n",
        "    # List of available models\n",
        "    models = ['EfficientNetB4', 'EfficientNetB4ST', 'EfficientNetAutoAttB4', 'EfficientNetAutoAttB4ST', 'FreqNet']\n",
        "\n",
        "    if uploaded_file:\n",
        "        selected_model = st.selectbox(\n",
        "            'Select model', models\n",
        "        )\n",
        "        # Assuming DFDC is the training dataset for the non-FreqNet models\n",
        "        selected_dataset = 'DFDC'\n",
        "\n",
        "        if st.button('Detect'):\n",
        "            with st.spinner('Analyzing file...'):\n",
        "                prediction, avg_score = detect_deep_fake(uploaded_file, selected_model, selected_dataset)\n",
        "\n",
        "            if uploaded_file.type.startswith('image'):\n",
        "                st.image(uploaded_file, caption='Uploaded image', width=500)\n",
        "            elif uploaded_file.type.startswith('video'):\n",
        "                st.video(uploaded_file, format='video/mp4')\n",
        "\n",
        "            st.markdown(f\"## **Detection Result: {prediction}**\")\n",
        "            st.write(f'Average Score (Probability of FAKE): {avg_score:.4f}')\n",
        "\n",
        "elif page == \"About the Author\":\n",
        "    st.title('About the Author')\n",
        "    st.markdown(\"### Name:\")\n",
        "    st.write(\"Nathalia Farinha Rodrigues\")\n",
        "    st.markdown(\"### Position:\")\n",
        "    st.write(\"Computer Vision Researcher at CPQD\")\n",
        "    st.markdown(\"### Thesis:\")\n",
        "    st.write(\"ANALYSIS OF DEEPFAKE DETECTION MODELS USING DEEP LEARNING\")\n",
        "    st.markdown(\"### Course:\")\n",
        "    st.write(\"Electrical Engineering\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit pyngrok"
      ],
      "metadata": {
        "id": "iBVW4vxNA84X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok, conf\n",
        "import subprocess\n",
        "import os\n",
        "import time\n",
        "\n",
        "# --- ngrok SETUP ---\n",
        "\n",
        "# NOTE: Paste your valid ngrok authentication token here\n",
        "# ngrok.set_auth_token(\"YOUR_NOGROK_AUTH_TOKEN_HERE\")\n",
        "ngrok.set_auth_token(\"xxx\")\n",
        "\n",
        "# Close old tunnels (if run before)\n",
        "print(\"Closing existing ngrok tunnels...\")\n",
        "ngrok.kill()\n",
        "\n",
        "# Open the tunnel for port 8501 (where Streamlit runs by default)\n",
        "print(\"Opening new ngrok tunnel...\")\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"\\nStreamlit Public URL:\", public_url)\n",
        "\n",
        "# Run Streamlit in the background\n",
        "# The shell command sends output logs to /content/logs.txt\n",
        "print(\"Starting Streamlit application in background...\")\n",
        "subprocess.Popen([\"streamlit\", \"run\", \"app.py\"], stdout=open(\"/content/logs.txt\", \"a\"), stderr=subprocess.STDOUT)\n",
        "\n",
        "# Give Streamlit a moment to start\n",
        "time.sleep(5)\n",
        "print(\"Setup complete. Access the application via the URL above.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvY9iDyEA8wX",
        "outputId": "cec60cdc-c776-4764-ec29-b3b7c2b890af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL pública do Streamlit: NgrokTunnel: \"https://95044cc8450d.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XMj-mEZ4A8tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIOPkHOCU_10"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}